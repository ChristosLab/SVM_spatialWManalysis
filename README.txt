				________

				 README
				________


Table of Contents
_________________

1 Project and directory structure
2 Important notes
.. 2.1 On functions and scripts
.. 2.2 On data structure
3 Data preparation
4 Data analysis
5 Questions the reader may have
.. 5.1 R: Column is constant and cannot be scaled
.. 5.2 MATLAB: Exporting CSVs takes such a long time that it appears the program is frozen
.. 5.3 I want to find more specifics on what functions output, what arguments they take, and so on
.. 5.4 When I add more neurons, the support vector machine does not perform with higher accuracy


1 Project and directory structure
=================================

   Top level  RData files; R/MATLAB project dirs  R functions stored here    
   data       Neuron data files; neuron lists                                
   doc        Analysis results and reports created manually                  
   figs       Figures for use in multiple output docs                        
   MATLAB     MATLAB functions and scripts; MATLAB outputs appear here first 
   output     Storage for program output: files are moved here manually      
   R          R scripts; R functions are stored in the top-level dir         


2 Important notes
=================

2.1 On functions and scripts
~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  A number of functions, some of which are compiled and made to
  cooperate in scripts, have been written by the writer to condense
  often-reused functions in the analysis of neural data.  A certain
  level of familiarity with MATLAB and R's built-in functions is
  assumed; the functions written for this analysis are briefly explained
  herein and documented further in their source files.


2.2 On data structure
~~~~~~~~~~~~~~~~~~~~~

  Data are stored in .mat files originally.  At the point where this
  analysis begins, they have already been processed through MATLAB.
  "Class," "response," and "stimulus location" are used interchangeably
  throughout this document; all of these refer to the initial location
  where the stimulus appears for the monkey in the match-nonmatch task.
  There are nine locations labeled 1-9.

  Data used for the support vector machine are organized into 180
  "trials" compiled from a number of trials.  Each file or dataframe (in
  R jargon) represents data from a single time period; each column is a
  neuron and each row is treated as an observation.  The leftmost column
  is the response variable, in this case the class or stimulus location.


3 Data preparation
==================

  Data is transferred from neuron data files to spreadsheet files for
  analysis using MATLAB.  Spreadsheets in the data directory contain
  neuron lists that are sorted into sustained and anticipatory using the
  working lab definition through the MATLAB classify() function.
  Filenames can be interpreted using the table below.

   pre   Pretraining                                               
   post  Posttraining                                              
   dl    Dorsolateral PFC                                          
   d     Dorsal PFC                                                
   all   All sampled neurons, even those that may not be selective 

  Note that lists are only of neurons that are selective for stimulus
  location unless "all" is in the filename.

  Running scriptInitialClassify.m in the MATLAB directory creates lists
  of neuron names in the workspace.  A prefix of i indicates that the
  neuron list also contains non-selective ("insignificant") neurons.
  Having these in the workspace is necessary for
  scriptOutputComparisonCSVs.m to work; this script processes neuron
  files to output CSVs of their firing rates over certain periods.

  A CSV outputted by scriptOutputComparisonCSVs.m has 180 rows and n + 1
  columns when representing a list of n neurons.  The first column is
  the response, that is, the class, in a 3x3 grid as shown below.

   4  3  2 
   5  9  1 
   6  7  8 

  There are 20 instances of each class, for a total of 180 instances
  over 9 classes.  Each column is a particular neuron's response.
  Neuron firings were not recorded simultaneously, so a certain amount
  of sameness across recording session is assumed.

  It is recommended that .csv files generated by
  scriptOutputComparisonCSVs.m be placed in the output directory after
  generation.  For a large number of neurons, generating these CSVs can
  take a very long time.

  The user can alter which time periods are outputted by
  scriptOutputComparisonCSVs.m; alternatively, CSVs can be made and
  saved from the MATLAB console using the same functions used in the
  script.  The script only saves data from certain time intervals, but
  data from other time intervals can be exported similarly with minimal
  changes.  This just involves changing the time interval arguments in
  the functions called in scriptOutputComparisonCSVs.m, which are
  documented in the functions themselves.


4 Data analysis
===============

  Support vector machines (SVMs) are easily created in R using the e1071
  package, which will probably have to be installed.  The file
  AccuracyTestingFunctions.r provides all tools necessary for fitting
  and comparing SVM fits.

  To load functions into R, give the console the command
  source("/this/is/a/path/to/file.r") or copy the functions desired
  directly into the console.  Sourcing from entire files when possible
  is preferable to avoid missing dependencies.

  The following functions are found in AccuracyTestingFunctions and
  sometimes depend on each other.  Any paths included in the functions
  may have to be changed.  Note that parameter selection for SVMs is
  almost always necessary (that is, changing the parameters from the
  defaults) in order to create a good model, if one exists.

  ImportNeuronData pulls the data from a .csv file specifically in the
  format outputted by scriptOutputComparisonCSVs.m and places it in the
  R project workspace with the filename sans extension.

  TestSVC ("test support vector classifier" because "machine" is the
  general term; something that outputs categorical data is technically a
  "classifier) divides data from a set of neurons in the workspace
  (i.e. "suspre0" from the default MATLAB export and R import processes)
  into training and testing sets, creates a support vector classifier on
  the training set, predicts the response variable for the testing set,
  and reports the training and testing accuracy.  Training accuracy is
  essentially always 100%.

  ReduceNeuronsTo is part of SampleTestSVC, which is used to subsample
  neurons (columns) in order to compare the amount of data compared in
  datasets with different numbers of neurons.  Essentially, if two
  datasets contain different numbers of neurons, a technique is to
  bootstrap (repeatedly subsample) from these neurons from the larger
  one so that the same number of neurons go into each model.  We do this
  for both datasets 100 or 1000 times and compare the average testing
  accuracy.  SampleTestSVC outputs a vector of testing accuracies, which
  can be compared using various statistical tests, graphed over time for
  datasets representing different points over the task, or used for
  anything else you want, really.

  SampleTestSVC and ImportNeuronData are the only essential functions in
  this source.


5 Questions the reader may have
===============================

5.1 R: Column is constant and cannot be scaled
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Some neurons have only a few nonzero firing rates during some time
  period.  Because a certain percentage of observations are used for
  training and the rest for testing, with such neurons, there is a
  nonnegligible chance of having a fully-zero column for either training
  or testing, despite the use of RemoveZeroCols(), which removes columns
  that are fully zero and are therefore useless.  As far as the writer
  can tell, these are not a problem becaues the failure to scale is just
  for the zero column, and of course a zero column does not need to be
  scaled anyway.  It has no effect on the model.

  This does however mean that some SVM tests for a particular dataset
  will have been made with more columns than SVM tests for another
  dataset.  When a neuron's data is unscalable in one of either training
  or testing, it is rendered useless for that test.


5.2 MATLAB: Exporting CSVs takes such a long time that it appears the program is frozen
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  Exporting CSVs can take a long time, depending mainly on the number of
  .mat files that have to be opened and closed in the process (that is
  the bottleneck).  If you are worried that the script is not working,
  pause and look at the incrementors in the workspace (i, j, etc.).  If
  the incrementors advance after the script is allowed to run and then
  paused again, the script is still running.

  Note that combining CSVs is possible, so this script should not be
  used to generate, for example, pre-and-post-sustained if pre-sustained
  and post-sustained have already been generated.  Just add the content
  of one CSV (sans the leftmost column, because this is the response) to
  the end (the right) of the other CSV.  LibreOffice Calc may have
  trouble with this because of the size of the data, but Microsoft Excel
  and probably other spreadsheet programs automatically expand to
  accommodate the data.


5.3 I want to find more specifics on what functions output, what arguments they take, and so on
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  There is more documentation in the files themselves, both in MATLAB
  and R scripts/functions.


5.4 When I add more neurons, the support vector machine does not perform with higher accuracy
~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~

  In a generalized linear model, we expect more data to result in higher
  accuracy.  A support vector machine attempts to divide results in a
  high-dimensional space (where each data column, in our case neuron,
  divides the data in a single dimension) and classify testing data
  based on these divisions.  Adding excess dimensions does not
  necessarily improve accuracy; therefore, it is advised that only
  neurons with high information content be included.

  It should also be noted that support vector machines, classifiers or
  otherwise, should have their parameters tweaked if optimal results are
  to be expected.  The default parameters are unlikely to work perfectly
  for all situations.
